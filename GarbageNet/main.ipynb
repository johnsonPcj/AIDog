{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scikit-learn\n",
    "#%pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ python train.py --dataset dataset --model output/fashion.model \\\n",
    "#\t--categorybin output/category_lb.pickle --colorbin output/color_lb.pickle\n",
    "\n",
    "#$ python classify.py --model output/fashion.model \\\n",
    "#\t--categorybin output/category_lb.pickle --colorbin output/color_lb.pickle \\\n",
    "#\t--image examples/black_jeans.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%run train.py --dataset dataset --model output/fashion.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run classify.py --model output/fashion.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image examples/black_jeans.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] data matrix: 92 images (5.39MB)\n",
      "[INFO] binarizing labels...\n",
      "[INFO] compiling model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liupl\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 15s 393ms/step - loss: 3.9649 - category_output_loss: 1.6325 - color_output_loss: 2.3325 - category_output_accuracy: 0.3992 - color_output_accuracy: 0.1798 - val_loss: 2.4830 - val_category_output_loss: 1.1315 - val_color_output_loss: 1.3515 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 3.6001 - category_output_loss: 1.4728 - color_output_loss: 2.1273 - category_output_accuracy: 0.3732 - color_output_accuracy: 0.2349 - val_loss: 2.6067 - val_category_output_loss: 1.2762 - val_color_output_loss: 1.3305 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 3.2892 - category_output_loss: 1.4500 - color_output_loss: 1.8391 - category_output_accuracy: 0.4540 - color_output_accuracy: 0.3641 - val_loss: 2.8603 - val_category_output_loss: 1.5286 - val_color_output_loss: 1.3318 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 3.2791 - category_output_loss: 1.2053 - color_output_loss: 2.0738 - category_output_accuracy: 0.4946 - color_output_accuracy: 0.2177 - val_loss: 3.1268 - val_category_output_loss: 1.7757 - val_color_output_loss: 1.3511 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 2.6026 - category_output_loss: 1.1267 - color_output_loss: 1.4759 - category_output_accuracy: 0.5224 - color_output_accuracy: 0.4685 - val_loss: 3.5503 - val_category_output_loss: 2.2083 - val_color_output_loss: 1.3419 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 2.8337 - category_output_loss: 0.7813 - color_output_loss: 2.0523 - category_output_accuracy: 0.6269 - color_output_accuracy: 0.3359 - val_loss: 3.7015 - val_category_output_loss: 2.3655 - val_color_output_loss: 1.3359 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 3.1980 - category_output_loss: 1.3883 - color_output_loss: 1.8097 - category_output_accuracy: 0.4044 - color_output_accuracy: 0.3049 - val_loss: 3.8211 - val_category_output_loss: 2.4675 - val_color_output_loss: 1.3535 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 3.2802 - category_output_loss: 1.2422 - color_output_loss: 2.0380 - category_output_accuracy: 0.5026 - color_output_accuracy: 0.3461 - val_loss: 3.9546 - val_category_output_loss: 2.5948 - val_color_output_loss: 1.3598 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 2.4853 - category_output_loss: 1.1023 - color_output_loss: 1.3829 - category_output_accuracy: 0.5076 - color_output_accuracy: 0.3005 - val_loss: 3.6211 - val_category_output_loss: 2.2724 - val_color_output_loss: 1.3486 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 2.7909 - category_output_loss: 0.8544 - color_output_loss: 1.9365 - category_output_accuracy: 0.7051 - color_output_accuracy: 0.3222 - val_loss: 3.7314 - val_category_output_loss: 2.3995 - val_color_output_loss: 1.3319 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 2.9536 - category_output_loss: 1.0021 - color_output_loss: 1.9515 - category_output_accuracy: 0.6403 - color_output_accuracy: 0.3633 - val_loss: 3.7544 - val_category_output_loss: 2.4394 - val_color_output_loss: 1.3150 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 2.0638 - category_output_loss: 0.6692 - color_output_loss: 1.3946 - category_output_accuracy: 0.6921 - color_output_accuracy: 0.4563 - val_loss: 3.8060 - val_category_output_loss: 2.5474 - val_color_output_loss: 1.2586 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 2.6496 - category_output_loss: 1.1825 - color_output_loss: 1.4670 - category_output_accuracy: 0.5563 - color_output_accuracy: 0.4275 - val_loss: 4.0228 - val_category_output_loss: 2.8087 - val_color_output_loss: 1.2141 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 2.2392 - category_output_loss: 0.9926 - color_output_loss: 1.2466 - category_output_accuracy: 0.6534 - color_output_accuracy: 0.5282 - val_loss: 4.0442 - val_category_output_loss: 2.8872 - val_color_output_loss: 1.1570 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 1.9769 - category_output_loss: 0.8070 - color_output_loss: 1.1699 - category_output_accuracy: 0.6722 - color_output_accuracy: 0.5164 - val_loss: 3.9595 - val_category_output_loss: 2.8737 - val_color_output_loss: 1.0858 - val_category_output_accuracy: 0.2000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 2.1290 - category_output_loss: 0.6033 - color_output_loss: 1.5257 - category_output_accuracy: 0.7251 - color_output_accuracy: 0.4143 - val_loss: 3.5807 - val_category_output_loss: 2.5119 - val_color_output_loss: 1.0687 - val_category_output_accuracy: 0.3000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 2.4646 - category_output_loss: 0.9194 - color_output_loss: 1.5452 - category_output_accuracy: 0.5967 - color_output_accuracy: 0.3992 - val_loss: 3.3211 - val_category_output_loss: 2.2673 - val_color_output_loss: 1.0538 - val_category_output_accuracy: 0.3000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 1.9587 - category_output_loss: 0.8864 - color_output_loss: 1.0723 - category_output_accuracy: 0.6209 - color_output_accuracy: 0.6096 - val_loss: 3.7663 - val_category_output_loss: 2.7523 - val_color_output_loss: 1.0140 - val_category_output_accuracy: 0.3000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.8809 - category_output_loss: 0.7021 - color_output_loss: 1.1788 - category_output_accuracy: 0.7477 - color_output_accuracy: 0.5372 - val_loss: 3.6970 - val_category_output_loss: 2.7144 - val_color_output_loss: 0.9826 - val_category_output_accuracy: 0.3000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 2.6714 - category_output_loss: 1.0753 - color_output_loss: 1.5961 - category_output_accuracy: 0.6333 - color_output_accuracy: 0.4175 - val_loss: 3.3353 - val_category_output_loss: 2.3843 - val_color_output_loss: 0.9510 - val_category_output_accuracy: 0.5000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 2.5290 - category_output_loss: 0.8230 - color_output_loss: 1.7060 - category_output_accuracy: 0.6488 - color_output_accuracy: 0.4085 - val_loss: 3.1893 - val_category_output_loss: 2.2593 - val_color_output_loss: 0.9300 - val_category_output_accuracy: 0.6000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 2.1099 - category_output_loss: 0.9573 - color_output_loss: 1.1526 - category_output_accuracy: 0.6163 - color_output_accuracy: 0.5666 - val_loss: 3.2071 - val_category_output_loss: 2.3341 - val_color_output_loss: 0.8730 - val_category_output_accuracy: 0.4000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 59ms/step - loss: 1.8933 - category_output_loss: 0.5727 - color_output_loss: 1.3206 - category_output_accuracy: 0.7850 - color_output_accuracy: 0.5116 - val_loss: 3.1510 - val_category_output_loss: 2.3312 - val_color_output_loss: 0.8197 - val_category_output_accuracy: 0.5000 - val_color_output_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 2.8047 - category_output_loss: 1.0325 - color_output_loss: 1.7722 - category_output_accuracy: 0.6570 - color_output_accuracy: 0.3969 - val_loss: 3.2207 - val_category_output_loss: 2.4375 - val_color_output_loss: 0.7831 - val_category_output_accuracy: 0.5000 - val_color_output_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 2.4358 - category_output_loss: 0.8747 - color_output_loss: 1.5611 - category_output_accuracy: 0.6806 - color_output_accuracy: 0.3543 - val_loss: 3.1789 - val_category_output_loss: 2.4627 - val_color_output_loss: 0.7162 - val_category_output_accuracy: 0.5000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 1.4850 - category_output_loss: 0.4670 - color_output_loss: 1.0180 - category_output_accuracy: 0.7834 - color_output_accuracy: 0.4987 - val_loss: 2.9538 - val_category_output_loss: 2.2859 - val_color_output_loss: 0.6680 - val_category_output_accuracy: 0.5000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 1.5753 - category_output_loss: 0.5459 - color_output_loss: 1.0294 - category_output_accuracy: 0.8237 - color_output_accuracy: 0.5311 - val_loss: 2.6277 - val_category_output_loss: 2.0110 - val_color_output_loss: 0.6167 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 1.9229 - category_output_loss: 0.7794 - color_output_loss: 1.1434 - category_output_accuracy: 0.6326 - color_output_accuracy: 0.5410 - val_loss: 2.6247 - val_category_output_loss: 2.0517 - val_color_output_loss: 0.5730 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 1.2796 - category_output_loss: 0.3734 - color_output_loss: 0.9061 - category_output_accuracy: 0.7700 - color_output_accuracy: 0.6205 - val_loss: 2.5228 - val_category_output_loss: 1.9834 - val_color_output_loss: 0.5393 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 1.4685 - category_output_loss: 0.5884 - color_output_loss: 0.8801 - category_output_accuracy: 0.8253 - color_output_accuracy: 0.6543 - val_loss: 2.4854 - val_category_output_loss: 1.9774 - val_color_output_loss: 0.5080 - val_category_output_accuracy: 0.6000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.7454 - category_output_loss: 0.7499 - color_output_loss: 0.9955 - category_output_accuracy: 0.7773 - color_output_accuracy: 0.6197 - val_loss: 2.0638 - val_category_output_loss: 1.5904 - val_color_output_loss: 0.4734 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 1.9241 - category_output_loss: 0.7530 - color_output_loss: 1.1711 - category_output_accuracy: 0.7316 - color_output_accuracy: 0.4771 - val_loss: 1.9187 - val_category_output_loss: 1.4698 - val_color_output_loss: 0.4489 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 1.7271 - category_output_loss: 0.6502 - color_output_loss: 1.0769 - category_output_accuracy: 0.7478 - color_output_accuracy: 0.5211 - val_loss: 1.9482 - val_category_output_loss: 1.5193 - val_color_output_loss: 0.4289 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 1.7451 - category_output_loss: 0.5210 - color_output_loss: 1.2241 - category_output_accuracy: 0.7718 - color_output_accuracy: 0.5412 - val_loss: 1.8068 - val_category_output_loss: 1.3780 - val_color_output_loss: 0.4287 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 1.7567 - category_output_loss: 0.6288 - color_output_loss: 1.1279 - category_output_accuracy: 0.7695 - color_output_accuracy: 0.5673 - val_loss: 1.7872 - val_category_output_loss: 1.3593 - val_color_output_loss: 0.4279 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 1.9984 - category_output_loss: 0.6757 - color_output_loss: 1.3227 - category_output_accuracy: 0.7706 - color_output_accuracy: 0.4834 - val_loss: 1.8767 - val_category_output_loss: 1.4525 - val_color_output_loss: 0.4242 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 1.4882 - category_output_loss: 0.4447 - color_output_loss: 1.0435 - category_output_accuracy: 0.8304 - color_output_accuracy: 0.5111 - val_loss: 1.9953 - val_category_output_loss: 1.5698 - val_color_output_loss: 0.4256 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 2s 71ms/step - loss: 1.3381 - category_output_loss: 0.3812 - color_output_loss: 0.9569 - category_output_accuracy: 0.8641 - color_output_accuracy: 0.6551 - val_loss: 1.8793 - val_category_output_loss: 1.4584 - val_color_output_loss: 0.4209 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 2.1225 - category_output_loss: 0.8425 - color_output_loss: 1.2800 - category_output_accuracy: 0.6807 - color_output_accuracy: 0.5343 - val_loss: 1.7945 - val_category_output_loss: 1.3643 - val_color_output_loss: 0.4302 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 1.3662 - category_output_loss: 0.3327 - color_output_loss: 1.0335 - category_output_accuracy: 0.8994 - color_output_accuracy: 0.6340 - val_loss: 1.9187 - val_category_output_loss: 1.5102 - val_color_output_loss: 0.4085 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 1s 66ms/step - loss: 1.4089 - category_output_loss: 0.4932 - color_output_loss: 0.9156 - category_output_accuracy: 0.7765 - color_output_accuracy: 0.6121 - val_loss: 1.8216 - val_category_output_loss: 1.4118 - val_color_output_loss: 0.4098 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.8559 - category_output_loss: 0.8060 - color_output_loss: 1.0498 - category_output_accuracy: 0.6705 - color_output_accuracy: 0.5871 - val_loss: 1.7180 - val_category_output_loss: 1.3100 - val_color_output_loss: 0.4080 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 1.4972 - category_output_loss: 0.6008 - color_output_loss: 0.8964 - category_output_accuracy: 0.7783 - color_output_accuracy: 0.5812 - val_loss: 1.6341 - val_category_output_loss: 1.2440 - val_color_output_loss: 0.3901 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.8324 - category_output_loss: 0.7648 - color_output_loss: 1.0676 - category_output_accuracy: 0.7324 - color_output_accuracy: 0.6165 - val_loss: 1.5054 - val_category_output_loss: 1.1540 - val_color_output_loss: 0.3514 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 57ms/step - loss: 1.1098 - category_output_loss: 0.3401 - color_output_loss: 0.7697 - category_output_accuracy: 0.8394 - color_output_accuracy: 0.6935 - val_loss: 1.5311 - val_category_output_loss: 1.1730 - val_color_output_loss: 0.3581 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.3036 - category_output_loss: 0.4262 - color_output_loss: 0.8774 - category_output_accuracy: 0.8550 - color_output_accuracy: 0.5818 - val_loss: 1.5150 - val_category_output_loss: 1.1515 - val_color_output_loss: 0.3635 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.2761 - category_output_loss: 0.4423 - color_output_loss: 0.8337 - category_output_accuracy: 0.8758 - color_output_accuracy: 0.6593 - val_loss: 1.7580 - val_category_output_loss: 1.4207 - val_color_output_loss: 0.3373 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.4216 - category_output_loss: 0.3633 - color_output_loss: 1.0583 - category_output_accuracy: 0.9027 - color_output_accuracy: 0.5158 - val_loss: 1.6342 - val_category_output_loss: 1.3026 - val_color_output_loss: 0.3316 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 1.0775 - category_output_loss: 0.2935 - color_output_loss: 0.7840 - category_output_accuracy: 0.8827 - color_output_accuracy: 0.6974 - val_loss: 1.5955 - val_category_output_loss: 1.2843 - val_color_output_loss: 0.3112 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 1.4162 - category_output_loss: 0.4809 - color_output_loss: 0.9353 - category_output_accuracy: 0.8641 - color_output_accuracy: 0.6693 - val_loss: 1.6925 - val_category_output_loss: 1.3600 - val_color_output_loss: 0.3325 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 1.3353 - category_output_loss: 0.5306 - color_output_loss: 0.8048 - category_output_accuracy: 0.7713 - color_output_accuracy: 0.7048 - val_loss: 1.6816 - val_category_output_loss: 1.3634 - val_color_output_loss: 0.3182 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.2395 - category_output_loss: 0.4002 - color_output_loss: 0.8394 - category_output_accuracy: 0.8758 - color_output_accuracy: 0.7423 - val_loss: 1.5477 - val_category_output_loss: 1.2299 - val_color_output_loss: 0.3177 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 1.3663 - category_output_loss: 0.3917 - color_output_loss: 0.9746 - category_output_accuracy: 0.8986 - color_output_accuracy: 0.5820 - val_loss: 1.5518 - val_category_output_loss: 1.2469 - val_color_output_loss: 0.3050 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.7163 - category_output_loss: 0.7733 - color_output_loss: 0.9430 - category_output_accuracy: 0.7184 - color_output_accuracy: 0.7246 - val_loss: 1.3955 - val_category_output_loss: 1.1086 - val_color_output_loss: 0.2869 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 1.4376 - category_output_loss: 0.5798 - color_output_loss: 0.8578 - category_output_accuracy: 0.8055 - color_output_accuracy: 0.7596 - val_loss: 1.9145 - val_category_output_loss: 1.6371 - val_color_output_loss: 0.2774 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 1.5003 - category_output_loss: 0.5219 - color_output_loss: 0.9785 - category_output_accuracy: 0.7750 - color_output_accuracy: 0.6386 - val_loss: 2.2564 - val_category_output_loss: 1.9696 - val_color_output_loss: 0.2867 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.5686 - category_output_loss: 0.7107 - color_output_loss: 0.8579 - category_output_accuracy: 0.7955 - color_output_accuracy: 0.6480 - val_loss: 2.1209 - val_category_output_loss: 1.8355 - val_color_output_loss: 0.2854 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.2244 - category_output_loss: 0.4747 - color_output_loss: 0.7497 - category_output_accuracy: 0.6999 - color_output_accuracy: 0.7465 - val_loss: 2.0814 - val_category_output_loss: 1.7860 - val_color_output_loss: 0.2955 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 1.5091 - category_output_loss: 0.5630 - color_output_loss: 0.9461 - category_output_accuracy: 0.7670 - color_output_accuracy: 0.6339 - val_loss: 1.9145 - val_category_output_loss: 1.6437 - val_color_output_loss: 0.2709 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.3540 - category_output_loss: 0.2237 - color_output_loss: 1.1304 - category_output_accuracy: 0.9538 - color_output_accuracy: 0.5183 - val_loss: 1.7670 - val_category_output_loss: 1.4825 - val_color_output_loss: 0.2844 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 1.5437 - category_output_loss: 0.7941 - color_output_loss: 0.7496 - category_output_accuracy: 0.7044 - color_output_accuracy: 0.8148 - val_loss: 1.7524 - val_category_output_loss: 1.4645 - val_color_output_loss: 0.2879 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 1.0472 - category_output_loss: 0.3808 - color_output_loss: 0.6664 - category_output_accuracy: 0.8613 - color_output_accuracy: 0.8178 - val_loss: 1.8970 - val_category_output_loss: 1.6001 - val_color_output_loss: 0.2969 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 1.5318 - category_output_loss: 0.5050 - color_output_loss: 1.0267 - category_output_accuracy: 0.8197 - color_output_accuracy: 0.6134 - val_loss: 1.7437 - val_category_output_loss: 1.4260 - val_color_output_loss: 0.3177 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 1.8611 - category_output_loss: 0.6504 - color_output_loss: 1.2107 - category_output_accuracy: 0.7767 - color_output_accuracy: 0.5661 - val_loss: 1.4604 - val_category_output_loss: 1.1687 - val_color_output_loss: 0.2917 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 1.0782 - category_output_loss: 0.3726 - color_output_loss: 0.7057 - category_output_accuracy: 0.8373 - color_output_accuracy: 0.7264 - val_loss: 1.4520 - val_category_output_loss: 1.1630 - val_color_output_loss: 0.2890 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 1.0586 - category_output_loss: 0.4193 - color_output_loss: 0.6393 - category_output_accuracy: 0.7837 - color_output_accuracy: 0.7249 - val_loss: 1.4799 - val_category_output_loss: 1.1971 - val_color_output_loss: 0.2828 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 56ms/step - loss: 1.6675 - category_output_loss: 0.7163 - color_output_loss: 0.9513 - category_output_accuracy: 0.7107 - color_output_accuracy: 0.6320 - val_loss: 1.4427 - val_category_output_loss: 1.1669 - val_color_output_loss: 0.2757 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.2378 - category_output_loss: 0.4575 - color_output_loss: 0.7803 - category_output_accuracy: 0.8508 - color_output_accuracy: 0.6784 - val_loss: 1.4666 - val_category_output_loss: 1.1923 - val_color_output_loss: 0.2743 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.1548 - category_output_loss: 0.2320 - color_output_loss: 0.9227 - category_output_accuracy: 0.9220 - color_output_accuracy: 0.6498 - val_loss: 1.4803 - val_category_output_loss: 1.2133 - val_color_output_loss: 0.2670 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 1.0842 - category_output_loss: 0.4802 - color_output_loss: 0.6040 - category_output_accuracy: 0.8478 - color_output_accuracy: 0.6741 - val_loss: 1.4455 - val_category_output_loss: 1.1561 - val_color_output_loss: 0.2893 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 1.2547 - category_output_loss: 0.6043 - color_output_loss: 0.6503 - category_output_accuracy: 0.8429 - color_output_accuracy: 0.7880 - val_loss: 1.4065 - val_category_output_loss: 1.0997 - val_color_output_loss: 0.3067 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 1.2076 - category_output_loss: 0.3917 - color_output_loss: 0.8159 - category_output_accuracy: 0.8290 - color_output_accuracy: 0.7202 - val_loss: 1.1188 - val_category_output_loss: 0.8212 - val_color_output_loss: 0.2976 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 1.0605 - category_output_loss: 0.4735 - color_output_loss: 0.5869 - category_output_accuracy: 0.8093 - color_output_accuracy: 0.7585 - val_loss: 1.0145 - val_category_output_loss: 0.7366 - val_color_output_loss: 0.2780 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.8836 - category_output_loss: 0.3488 - color_output_loss: 0.5349 - category_output_accuracy: 0.8523 - color_output_accuracy: 0.7991 - val_loss: 1.3396 - val_category_output_loss: 1.0861 - val_color_output_loss: 0.2535 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 1.4768 - category_output_loss: 0.6427 - color_output_loss: 0.8340 - category_output_accuracy: 0.7896 - color_output_accuracy: 0.6832 - val_loss: 1.4217 - val_category_output_loss: 1.2047 - val_color_output_loss: 0.2170 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 1.1717 - category_output_loss: 0.5209 - color_output_loss: 0.6509 - category_output_accuracy: 0.8076 - color_output_accuracy: 0.6711 - val_loss: 1.2783 - val_category_output_loss: 1.0708 - val_color_output_loss: 0.2075 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 1.1683 - category_output_loss: 0.2587 - color_output_loss: 0.9095 - category_output_accuracy: 0.8532 - color_output_accuracy: 0.6358 - val_loss: 1.2211 - val_category_output_loss: 1.0346 - val_color_output_loss: 0.1865 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 1.0812 - category_output_loss: 0.3616 - color_output_loss: 0.7197 - category_output_accuracy: 0.8294 - color_output_accuracy: 0.6529 - val_loss: 1.2721 - val_category_output_loss: 1.0761 - val_color_output_loss: 0.1960 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.2919 - category_output_loss: 0.3965 - color_output_loss: 0.8955 - category_output_accuracy: 0.8754 - color_output_accuracy: 0.6598 - val_loss: 1.1188 - val_category_output_loss: 0.9050 - val_color_output_loss: 0.2138 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.0461 - category_output_loss: 0.3206 - color_output_loss: 0.7255 - category_output_accuracy: 0.8486 - color_output_accuracy: 0.6838 - val_loss: 1.3007 - val_category_output_loss: 1.0730 - val_color_output_loss: 0.2277 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 1s 67ms/step - loss: 1.4169 - category_output_loss: 0.5488 - color_output_loss: 0.8681 - category_output_accuracy: 0.7886 - color_output_accuracy: 0.6338 - val_loss: 1.4677 - val_category_output_loss: 1.1945 - val_color_output_loss: 0.2732 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 1.2134 - category_output_loss: 0.4074 - color_output_loss: 0.8060 - category_output_accuracy: 0.8154 - color_output_accuracy: 0.7172 - val_loss: 1.3444 - val_category_output_loss: 1.0906 - val_color_output_loss: 0.2538 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 1.3005 - category_output_loss: 0.5672 - color_output_loss: 0.7333 - category_output_accuracy: 0.7951 - color_output_accuracy: 0.7259 - val_loss: 0.9597 - val_category_output_loss: 0.7065 - val_color_output_loss: 0.2532 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 2.1471 - category_output_loss: 0.8741 - color_output_loss: 1.2730 - category_output_accuracy: 0.7371 - color_output_accuracy: 0.5802 - val_loss: 1.0179 - val_category_output_loss: 0.8049 - val_color_output_loss: 0.2130 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.9357 - category_output_loss: 0.2862 - color_output_loss: 0.6496 - category_output_accuracy: 0.8609 - color_output_accuracy: 0.7615 - val_loss: 0.9055 - val_category_output_loss: 0.7278 - val_color_output_loss: 0.1777 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 1.5304 - category_output_loss: 0.6260 - color_output_loss: 0.9044 - category_output_accuracy: 0.7422 - color_output_accuracy: 0.7128 - val_loss: 0.8992 - val_category_output_loss: 0.7320 - val_color_output_loss: 0.1672 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.0350 - category_output_loss: 0.3847 - color_output_loss: 0.6503 - category_output_accuracy: 0.8491 - color_output_accuracy: 0.6995 - val_loss: 1.1025 - val_category_output_loss: 0.9221 - val_color_output_loss: 0.1804 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 1.0625 - category_output_loss: 0.3865 - color_output_loss: 0.6760 - category_output_accuracy: 0.8793 - color_output_accuracy: 0.7819 - val_loss: 1.0442 - val_category_output_loss: 0.8740 - val_color_output_loss: 0.1702 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 53ms/step - loss: 1.0691 - category_output_loss: 0.3430 - color_output_loss: 0.7261 - category_output_accuracy: 0.8569 - color_output_accuracy: 0.6923 - val_loss: 1.0601 - val_category_output_loss: 0.8728 - val_color_output_loss: 0.1873 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 1.2360 - category_output_loss: 0.6185 - color_output_loss: 0.6175 - category_output_accuracy: 0.7854 - color_output_accuracy: 0.7044 - val_loss: 1.0149 - val_category_output_loss: 0.8291 - val_color_output_loss: 0.1858 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 1.2290 - category_output_loss: 0.3154 - color_output_loss: 0.9135 - category_output_accuracy: 0.9117 - color_output_accuracy: 0.7975 - val_loss: 0.9627 - val_category_output_loss: 0.7733 - val_color_output_loss: 0.1894 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.9316 - category_output_loss: 0.3958 - color_output_loss: 0.5358 - category_output_accuracy: 0.8348 - color_output_accuracy: 0.7732 - val_loss: 1.0424 - val_category_output_loss: 0.8399 - val_color_output_loss: 0.2025 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 1.5515 - category_output_loss: 0.5901 - color_output_loss: 0.9614 - category_output_accuracy: 0.7915 - color_output_accuracy: 0.7311 - val_loss: 0.9956 - val_category_output_loss: 0.7945 - val_color_output_loss: 0.2011 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.9355 - category_output_loss: 0.3931 - color_output_loss: 0.5424 - category_output_accuracy: 0.8857 - color_output_accuracy: 0.7988 - val_loss: 1.0979 - val_category_output_loss: 0.8904 - val_color_output_loss: 0.2075 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.7901 - category_output_loss: 0.2660 - color_output_loss: 0.5241 - category_output_accuracy: 0.9181 - color_output_accuracy: 0.7526 - val_loss: 1.2475 - val_category_output_loss: 1.0245 - val_color_output_loss: 0.2230 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.8790 - category_output_loss: 0.3327 - color_output_loss: 0.5464 - category_output_accuracy: 0.8908 - color_output_accuracy: 0.7668 - val_loss: 1.2149 - val_category_output_loss: 0.9813 - val_color_output_loss: 0.2336 - val_category_output_accuracy: 0.7000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.7412 - category_output_loss: 0.3078 - color_output_loss: 0.4334 - category_output_accuracy: 0.9124 - color_output_accuracy: 0.8474 - val_loss: 1.2571 - val_category_output_loss: 1.0395 - val_color_output_loss: 0.2176 - val_category_output_accuracy: 0.8000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.8974 - category_output_loss: 0.2704 - color_output_loss: 0.6270 - category_output_accuracy: 0.8964 - color_output_accuracy: 0.7298 - val_loss: 1.1431 - val_category_output_loss: 0.9202 - val_color_output_loss: 0.2229 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 1.4873 - category_output_loss: 0.5268 - color_output_loss: 0.9606 - category_output_accuracy: 0.7963 - color_output_accuracy: 0.7184 - val_loss: 1.0217 - val_category_output_loss: 0.8105 - val_color_output_loss: 0.2112 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 1.4626 - category_output_loss: 0.5836 - color_output_loss: 0.8791 - category_output_accuracy: 0.8387 - color_output_accuracy: 0.7431 - val_loss: 0.9957 - val_category_output_loss: 0.7885 - val_color_output_loss: 0.2072 - val_category_output_accuracy: 0.9000 - val_color_output_accuracy: 0.9000\n",
      "[INFO] serializing network...\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "output/fruits.model is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\liujun\\mylab\\python-AI\\ClassDelivery\\Class9\\FruitNet\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;31m# save the model to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] serializing network...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m# save the category binarizer to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2085\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 2087\u001b[1;33m                     signatures, options, save_traces)\n\u001b[0m\u001b[0;32m   2088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2089\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m--> 151\u001b[1;33m                             signatures, options, save_traces)\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[1;32m---> 91\u001b[1;33m           model, filepath, signatures, options)\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, raise_metadata_warning, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1108\u001b[0m   \u001b[1;31m# the SavedModel proto itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexperimental_skip_checkpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m     \u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m     ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[0;32m   1112\u001b[0m         experimental_io_device=options.experimental_io_device)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\saved_model\\utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    218\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m   \"\"\"\n\u001b[1;32m--> 499\u001b[1;33m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m   \"\"\"\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: output/fruits.model is not a directory"
     ]
    }
   ],
   "source": [
    "%run train.py --dataset MyDataset --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liupl\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7F2207C18> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F2207C18>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7F2207C18> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F2207C18>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[INFO] category: banana (98.39%)\n",
      "[INFO] color: yellow (95.14%)\n",
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7F226ADC8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F226ADC8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7F226ADC8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F226ADC8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[INFO] category: grape (99.93%)\n",
      "[INFO] color: purple (90.02%)\n",
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7F0FCE798> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F0FCE798>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7F0FCE798> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F0FCE798>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[INFO] category: apple (89.21%)\n",
      "[INFO] color: yellow (96.68%)\n",
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7F9B5DCA8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F9B5DCA8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7F9B5DCA8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7F9B5DCA8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[INFO] category: apple (99.84%)\n",
      "[INFO] color: red (91.94%)\n",
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7EC057A68> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7EC057A68>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7EC057A68> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7EC057A68>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7EBC3E708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[INFO] category: grape (99.77%)\n",
      "[INFO] color: green (65.32%)\n",
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7EBBC1F78> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7EBBC1F78>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7EBBC1F78> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7EBBC1F78>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7E2F469D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[INFO] category: apple (99.91%)\n",
      "[INFO] color: green (93.30%)\n",
      "[INFO] loading network...\n",
      "[INFO] classifying image...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001E7EBBA55E8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7EBBA55E8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001E7EBBA55E8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001E7EBBA55E8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[INFO] category: apple (99.57%)\n",
      "[INFO] color: green (52.87%)\n"
     ]
    }
   ],
   "source": [
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/1.jpg\n",
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/2.jpg\n",
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/3.jpg\n",
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/4.jpg\n",
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/5.jpg\n",
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/6.jpg\n",
    "%run classify.py --model output/fruits.model --categorybin output/category_lb.pickle --colorbin output/color_lb.pickle --image MyExamples/7.jpg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
